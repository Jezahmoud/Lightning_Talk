{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "format:\n",
        "  revealjs: \n",
        "    theme: [moon]\n",
        "    highlight-style: arrow-light\n",
        "    incremental: true\n",
        "editor: visual\n",
        "---"
      ],
      "id": "b7523def"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  {background-image=\"explainable_AI_shutterstock_-BAIVECTOR.jpeg\"}\n",
        "\n",
        "# Outline of the Talk\n",
        "\n",
        "-   Introduction\n",
        "\n",
        "-   Answering a few questions about XAI\n",
        "\n",
        "-   Common XAI uses\n",
        "\n",
        "-   R packages for XAI\n",
        "\n",
        "-   Implementation\n",
        "\n",
        "-   Conclusion\\\n",
        "\n",
        "# Introduction\n",
        "\n",
        "Have you ever been curious about how machine learning works? Or, what is happening inside these models, and to what extent can we rely on their predictions?\n",
        "\n",
        "# What is XAI?\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "-   Explainable AI (XAI) is a new subfield of machine learning (ML).\n",
        ":::\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "-   Methods for describing the underlying decision-making process of machine learning models\n",
        ":::\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "-   XAI has many branches, but it generally tries to explain the results of complex black-box ML models.\n",
        ":::\n",
        "\n",
        "::: {.fragment .fade-in}\n",
        "-   Model-agnostic XAI is the most widely used approach.\n",
        ":::\n",
        "\n",
        "# The worldwide interest of XAI\n",
        "\n",
        "::: {style=\"text-align: center; margin-top: 1em\"}\n",
        "[Google Trend](https://trends.google.com/trends/explore?date=today%205-y&q=explainable%20ai){style=\"text-align: center\"}\n",
        ":::\n",
        "\n",
        "# Why do we need XAI?\n",
        "\n",
        "-   Current advances in deep learning (DL), having a few million parameters is typical for a DL model!\n",
        "\n",
        "-   Comparing this number of parameters with the simple linear regression model we've been using for decades will give you a sense of how complicated these DL models are.\n",
        "\n",
        "# When do we need XAI?\n",
        "\n",
        "-   In every ML project, at some point, you will probably need to provide the decision-making procedure of the deployed ML models to your clients or your colleagues.\n",
        "\n",
        "-   XAI is crucial in applications of ML in which the decision of the ML system has a direct impact on people's lives or a significant impact on society.\n",
        "\n",
        "# Some common use cases of XAI\n",
        "\n",
        "![](1_28Zt-BgUk0a91pQGNBzgLA@2x.jpeg){fig-align=\"center\"}\n",
        "\n",
        "# Some common use cases of XAI\n",
        "\n",
        "![](1_0AR4X1BH2DaLMIcABBl6Gw@2x.jpeg){fig-align=\"center\"}\n",
        "\n",
        "## R packages for XAI {.smaller}\n",
        "\n",
        "| Package          | Description                                                                                                         |\n",
        "|-----------------------|-------------------------------------------------|\n",
        "| `DALEX`          | The DALEX package (Descriptive mAchine Learning EXplanations) helps to understand how complex models are working.   |\n",
        "| ~~`iBreakDown`~~ | The iBreakDown package is a model agnostic tool for explanation of predictions from black boxes ML models.          |\n",
        "| ~~`fairmodels`~~ | Flexible tool for bias detection, visualization, and mitigation.                                                    |\n",
        "| `modelStudio`    | The modelStudio package automates the explanatory analysis of machine learning predictive models.                   |\n",
        "| ~~`arenar`~~     | Arena is an interactive tool that allows you to explore and compare any model regardless of its internal structure. |\n",
        "\n",
        "# Collection of tools\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "%%| fig-width: 10\n",
        "%%| fig-height: 5\n",
        "flowchart TD\n",
        "    B[\"fab:fa-twitter The DrWhy.AI\"]\n",
        "    style B fill:#bbf,stroke:#333,stroke-width:4px\n",
        "    B==>C[fa:fa-ban DALEX]\n",
        "    style C fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "    B==>D(iBreakDown);\n",
        "    style D fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "    B==>E(fairmodels)\n",
        "    style E fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "    B==>F(modelStudio)\n",
        "    style F fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "    B==>G(arenar)\n",
        "    style G fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "```\n",
        "\n",
        "\n",
        "::: footer\n",
        "Learn more: [The DrWhy.AI](https://github.com/ModelOriented/DrWhy)\n",
        ":::\n",
        "\n",
        "\n",
        "# Jeza\n",
        "\n",
        "\n",
        "```{code}\n",
        "flowchart TD;\n",
        "\n",
        "    B[\"fab:fa-twitter The DrWhy.AI\"]\n",
        "\n",
        "    style B fill:#bbf,stroke:#333,stroke-width:4px\n",
        "\n",
        "    B==>C[fa:fa-ban DALEX]\n",
        "\n",
        "    style C fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "\n",
        "    B==>D(iBreakDown);\n",
        "\n",
        "    style D fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "\n",
        "    B==>E(fairmodels)\n",
        "\n",
        "    style E fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "\n",
        "    B==>F(modelStudio)\n",
        "\n",
        "    style F fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "\n",
        "    B==>G(arenar)\n",
        "\n",
        "    style G fill:#bbf,stroke:#ff56,stroke-width:2px,color:#fff,stroke-dasharray: 5 5\n",
        "```\n",
        "\n",
        "\n",
        "# Categorization of XAI\n",
        "\n",
        "\n",
        "```{mermaid}\n",
        "flowchart TB;\n",
        " \n",
        "    subgraph Scope\n",
        "    A[Global Explination] === B[Explinaing the whole model]\n",
        "    style A fill:#bbf,stroke:#333,stroke-width:4px\n",
        "    C[Local Explination] === D[Expliaing a specific model]\n",
        "    style C fill:#bbf,stroke:#333,stroke-width:4px\n",
        "    end\n",
        "    subgraph Agnosticity\n",
        "    E[Model-agnostic] === F[Application to all model types]\n",
        "    style E fill:#bbf,stroke:#333,stroke-width:4px\n",
        "    G[Model-specific] === I[Only applicable to a specific model type]\n",
        "    style G fill:#bbf,stroke:#333,stroke-width:4px\n",
        "    end\n",
        "```\n",
        "\n",
        "\n",
        "# Implementation\n",
        "\n",
        "# Conclusion"
      ],
      "id": "d1a7f183"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}