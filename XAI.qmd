---
format:
  revealjs:
    theme: moon
    highlight-style: arrow-light
    incremental: true
    include-before: |
      <style>
      .reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5, .reveal h6 {
          text-transform: none !important;
      }
      </style>
editor: visual

---

#  {background-image="Jeza Allohibi.png"}

# Outline

-   Introduction

-   Answering a few questions about XAI

-   Common XAI uses

-   R packages for XAI

-   Implementation

-   Conclusion\

# Introduction

Have you ever been curious about how machine learning works? Or, what is happening inside these models, and to what extent can we rely on their predictions?

# What is XAI?

::: {.fragment .fade-in}
-   Explainable AI (XAI) is a branch of artificial intelligence
:::

::: {.fragment .fade-in}
-   Methods for describing the underlying decision-making process of machine learning models
:::

::: {.fragment .fade-in}
-   It generally tries to explain the results of complex black-box ML models.
:::

# The worldwide interest of XAI

Over the past five years, the rate of interest has been rising steadily [(google trend)](https://trends.google.com/trends/explore?date=today%205-y&q=explainable%20ai)

# Why do we need XAI?

::: {.fragment .fade-in}
-   Current advances in deep learning (DL) mean that having a few million parameters in a DL model is typical.
:::

::: {.fragment .fade-in}
-   Comparing this number of parameters with the simple linear regression models we have been using for decades can give you a sense of how much more complicated these DL models are.
:::

# When do we need XAI?

::: {.fragment .fade-in}
-   In every ML project, there will likely come a time when you need to explain the decision-making process of the deployed ML models to your clients or colleagues.
:::

::: {.fragment .fade-in}
-   XAI is crucial in applications of ML where the system's decisions have a direct impact on people's lives or a significant impact on society.
:::

## Some common use cases of XAI

![](case%20of%20XAI_1.jpeg){fig-align="center" width="750"}

![](case%20of%20XAI_3.png){fig-align="center" width="1031"}

# Some common use cases of XAI

![](case%20of%20XAI_2.jpeg){fig-align="center"}

## R packages for XAI {.smaller}

| Package          | Description                                                                                                         |
|----------------------|-------------------------------------------------|
| `DALEX`          | The DALEX package (Descriptive mAchine Learning EXplanations) helps to understand how complex models are working.   |
| ~~`iBreakDown`~~ | The iBreakDown package is a model agnostic tool for explanation of predictions from black boxes ML models.          |
| ~~`fairmodels`~~ | Flexible tool for bias detection, visualization, and mitigation.                                                    |
| `modelStudio`    | The modelStudio package automates the explanatory analysis of machine learning predictive models.                   |
| ~~`arenar`~~     | Arena is an interactive tool that allows you to explore and compare any model regardless of its internal structure. |

# Collection of tools

![](collection%20of%20tools.png){fig-align="center"}

::: footer
Learn more: [The DrWhy.AI](https://github.com/ModelOriented/DrWhy)
:::

# Categorization of XAI

![](Categorization%20of%20XAI.png){fig-align="center" width="179"}

## Implementation

::: panel-tabset
### Black box

![](black%20box.png){fig-align="center"}

### Part I

```{r}
#| echo: true
#| eval: false
#| code-fold: true
library(modelStudio)
library(DALEX)
library(tidyverse)
library(tidymodels)
library(xgboost)
```

### Part II

``` {.r code-line-numbers="3-4|8|13"}
# DATA

data_tbl <- mpg %>%
  select(hwy, manufacturer:drv, fl, class)

# MODEL

fit_xgboost <- boost_tree(learn_rate = 0.3) %>%
  set_mode("regression") %>%
  set_engine("xgboost") %>%
  fit(hwy ~ ., data = data_tbl)

fit_xgboost
```

### Part III

``` {.r code-line-numbers="3|12"}
# EXPLAINER

explainer <- DALEX::explain(
  model = fit_xgboost,
  data  = data_tbl,
  y     = data_tbl$hwy,
  label = "XGBoost"
)

# MODEL STUDIO

modelStudio::modelStudio(explainer)
```

::: footer
Final output: [Interactive XAI](https://rpubs.com/MLexpert/971057)
:::
:::

# Conclusion

::: {.fragment .fade-in}
-   Over the past five years, there has been an increase in the number of searches conducted about XAI, indicating growing interest and awareness.
:::

::: {.fragment .fade-in}
-   XAI has become a key component of today's advanced AI systems, facilitating easier collaboration between humans and machines by making AI decisions more understandable.
:::

## Reference

1.  [Explanatory Model Analysis](https://ema.drwhy.ai/)

2.  [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/)

3.  [Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI](https://www.sciencedirect.com/science/article/abs/pii/S1566253519308103?via%3Dihub)

4.  [Global Aggregations of Local Explanations for Black Box models](https://arxiv.org/pdf/1907.03039.pdf)

::: {style="text-align: center; margin-top: 1em"}
# Thank You
:::
